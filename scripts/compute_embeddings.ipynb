{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "{'image_path': 'data/GES800/M01_Présentation_du_cours/page_18.png', 'module': 'M01_Présentation_du_cours', 'page': 'page_18.png', 'content': \"La diapositive présente les informations concernant les modalités pour contacter la personne qui a créé la présentation. Elle indique qu'elle n'a pas de bureau à l'ÉTS (École de technologie supérieure) et qu'il est possible de la rencontrer sur rendez-vous avant le cours.\"}\n",
      "<class 'dict'>\n",
      "252\n",
      "<class 'list'>\n",
      "<class 'str'>\n",
      "La diapositive présente les informations concernant les modalités pour contacter la personne qui a créé la présentation. Elle indique qu'elle n'a pas de bureau à l'ÉTS (École de technologie supérieure) et qu'il est possible de la rencontrer sur rendez-vous avant le cours.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse each line as a JSON object\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "# Usage\n",
    "file_path = '../data/GES800/embeds/summaries_GES800.jsonl'  # Replace with the path to your JSONL file\n",
    "contents = load_jsonl(file_path)\n",
    "print(len(contents))\n",
    "print(contents[0])\n",
    "print(type(contents[0]))\n",
    "\n",
    "text_contents = [slide['content'] for slide in contents]\n",
    "print(len(text_contents))\n",
    "print(type(text_contents))\n",
    "print(type(text_contents[0]))\n",
    "print(text_contents[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 252 1024\n",
      "(252, 1024)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cohere\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model_name = \"embed-multilingual-v3.0\"\n",
    "api_key: str | None = os.getenv(\"COHERE_API_KEY\")\n",
    "input_type_embed = \"search_document\"\n",
    "\n",
    "# Now we'll set up the cohere client.\n",
    "if api_key is None:\n",
    "    raise ValueError(\"Please set the COHERE_API_KEY environment variable.\")\n",
    "co = cohere.Client(api_key)\n",
    "\n",
    "# Get the embeddings\n",
    "embeds: list[list[float]] = co.embed(\n",
    "    texts=text_contents, model=model_name, input_type=input_type_embed\n",
    ").embeddings\n",
    "\n",
    "# print(embeds)\n",
    "print(type(embeds), len(embeds), len(embeds[0]))\n",
    "array_embeds = np.array(embeds)\n",
    "print(array_embeds.shape)\n",
    "np.save('../data/GES800/embeds/embeddings_GES800.npy', array_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity_matrix(vectors, query_vec):\n",
    "    dot_product = np.dot(vectors, query_vec)\n",
    "    \n",
    "    norms_vectors = np.linalg.norm(vectors, axis=1)\n",
    "    norm_query_vec = np.linalg.norm(query_vec)\n",
    "    \n",
    "    if norm_query_vec == 0 or np.any(norms_vectors == 0):\n",
    "        raise ValueError(\"Cosine similarity is not defined when one or both vectors are zero vectors.\")\n",
    "    \n",
    "    similarity = dot_product / (norms_vectors * norm_query_vec)\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cohere\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model_name = \"embed-multilingual-v3.0\"\n",
    "api_key: str | None = os.getenv(\"COHERE_API_KEY\")\n",
    "input_type_embed = \"search_query\"\n",
    "\n",
    "QUERY=\"Comment gérer un projet de développement de produits ?\"\n",
    "\n",
    "# Now we'll set up the cohere client.\n",
    "if api_key is None:\n",
    "    raise ValueError(\"Please set the COHERE_API_KEY environment variable.\")\n",
    "co = cohere.Client(api_key)\n",
    "\n",
    "# Get the embeddings\n",
    "query_embed: list[list[float]] = co.embed(\n",
    "    texts=[QUERY], model=model_name, input_type=input_type_embed\n",
    ").embeddings\n",
    "query_array = np.array(query_embed)\n",
    "query_array = query_array.reshape(-1)\n",
    "\n",
    "embeds_dataset = np.load('../data/GES800/embeds/embeddings_GES800.npy')\n",
    "\n",
    "similarity_results = np.zeros((embeds_dataset.shape[0],), dtype=np.float32)\n",
    "try:\n",
    "    similarity_results = cosine_similarity_matrix(embeds_dataset, query_array)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "\n",
    "sorted_indices = np.argsort(similarity_results)[::-1]\n",
    "relevant_contents: list[dict] = [contents[i] for i in sorted_indices[:5]]\n",
    "print(relevant_contents)\n",
    "for i in range(8):\n",
    "    print(similarity_results[sorted_indices[i]], contents[sorted_indices[i]])\n",
    "\n",
    "# -----------------------------------------------\n",
    "from openai import OpenAI\n",
    "def extract_tags_function_call(input: str, model: str, max_retries: int = 1):\n",
    "    client = OpenAI()\n",
    "    try:\n",
    "        extracted_details = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a world class teacher in the field of management and supervision of teams working on projects. You will answer questions asked by students. You will use theory provided to you in the form of slides.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": input,\n",
    "                },\n",
    "            ],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return extracted_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"Error generating post with the OpenAI API: {e}\"\n",
    "\n",
    "for d in relevant_contents:\n",
    "    d.pop(\"image_path\", None)\n",
    "\n",
    "input_prompt = f\"REMEMBER TO USE THE THEORY GIVEN TO YOU. But not all of it might be relevant to the question. Here is the student's question: {QUERY}\\n, and the relevant theory: {relevant_contents}. Give a clear answer that helps the student understand the course material. Cite the sources you used to answer the question. Cite the module and the page you used.\"\n",
    "answer = extract_tags_function_call(input_prompt, \"gpt-3.5-turbo-0125\")\n",
    "print('\\n')\n",
    "print(answer.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
